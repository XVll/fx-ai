diff --git a/agent/ppo_agent.py b/agent/ppo_agent.py
index 39f46f2..68627fb 100644
--- a/agent/ppo_agent.py
+++ b/agent/ppo_agent.py
@@ -244,7 +244,6 @@ class PPOTrainer:
     def compute_advantages(self) -> None:
         """
         Compute advantages and returns using Generalized Advantage Estimation (GAE).
-        Simplified version to avoid gradient and shape issues.
         """
         # Make sure buffer data is prepared
         if isinstance(self.buffer.rewards, list):
@@ -255,43 +254,29 @@ class PPOTrainer:
         values = self.buffer.values
         dones = self.buffer.dones
 
-        # Make sure all tensors are on CPU and detached from computation graph
-        rewards = rewards.detach().cpu()
-        values = values.detach().cpu()
-        dones = dones.detach().cpu()
+        # Convert to NumPy arrays for easier processing
+        rewards_np = rewards.detach().cpu().numpy()
+        values_np = values.detach().cpu().numpy()
+        dones_np = dones.detach().cpu().numpy()
 
-        # Ensure consistent shapes for all tensors
-        if len(rewards.shape) == 1:
-            rewards = rewards.unsqueeze(1)
-        if len(values.shape) == 1:
-            values = values.unsqueeze(1)
-        if len(dones.shape) == 1:
-            dones = dones.unsqueeze(1)
-
-        # Create tensors for advantages and returns with correct shape
-        advantages = torch.zeros_like(rewards)
-        returns = torch.zeros_like(rewards)
+        # Create NumPy array for advantages
+        advantages_np = np.zeros_like(rewards_np)
 
         # Log shapes for debugging
         self.logger.info(
             f"Computing advantages - rewards: {rewards.shape}, values: {values.shape}, dones: {dones.shape}")
 
-        # Compute GAE using numpy to avoid building computation graph
-        rewards_np = rewards.numpy()
-        values_np = values.numpy()
-        dones_np = dones.numpy()
-
-        # Compute advantages
+        # Compute GAE
         last_gae = 0
         for t in reversed(range(len(rewards_np))):
             # End of episode or end of buffer
             if t == len(rewards_np) - 1:
                 # For the last step, use 0 as the next value
                 next_value = 0
-                next_non_terminal = 1.0 - float(dones_np[t])
+                next_non_terminal = 1.0 - float(dones_np[t, 0])  # Extract scalar value
             else:
                 next_value = values_np[t + 1, 0]
-                next_non_terminal = 1.0 - float(dones_np[t])
+                next_non_terminal = 1.0 - float(dones_np[t, 0])  # Extract scalar value
 
             # TD error
             delta = rewards_np[t, 0] + self.gamma * next_value * next_non_terminal - values_np[t, 0]
@@ -299,16 +284,13 @@ class PPOTrainer:
             # Recursive GAE formula
             last_gae = delta + self.gamma * self.gae_lambda * next_non_terminal * last_gae
 
-            # Store advantage
-            advantages[t, 0] = last_gae
+            # Store advantage in NumPy array
+            advantages_np[t, 0] = last_gae
 
-        # Returns = advantages + values
+        # Convert back to PyTorch tensors
+        advantages = torch.FloatTensor(advantages_np).to(self.device)
         returns = advantages + values
 
-        # Convert back to same device as model
-        advantages = advantages.to(self.device)
-        returns = returns.to(self.device)
-
         # Store in buffer
         self.buffer.advantages = advantages
         self.buffer.returns = returns
diff --git a/config/data/databento.yaml b/config/data/databento.yaml
index 07c945b..dfb7bbb 100644
--- a/config/data/databento.yaml
+++ b/config/data/databento.yaml
@@ -12,7 +12,7 @@ dbn_cache_size: 32
 use_cache: true
 
 # Data parameters
-symbols: ["MLGO"]  # Default trading symbol
+symbol: "MLGO"  # Default trading symbol
 start_date: "2025-03-27"
 end_date: "2025-03-27"
 
diff --git a/data/__pycache__/data_processor.cpython-310.pyc b/data/__pycache__/data_processor.cpython-310.pyc
index 317b64d..1c5c291 100644
Binary files a/data/__pycache__/data_processor.cpython-310.pyc and b/data/__pycache__/data_processor.cpython-310.pyc differ
diff --git a/data/data_manager.py b/data/data_manager.py
index ce23967..36bc376 100644
--- a/data/data_manager.py
+++ b/data/data_manager.py
@@ -4,7 +4,7 @@ import pandas as pd
 from datetime import datetime
 import logging
 
-from data.provider.data_provider import DataProvider, HistoricalDataProvider
+from data.provider.data_provider import DataProvider, HistoricalDataProvider, LiveDataProvider
 from data.utils.helpers import ensure_timezone_aware
 
 
diff --git a/data/feature/__pycache__/feature_extractor.cpython-310.pyc b/data/feature/__pycache__/feature_extractor.cpython-310.pyc
deleted file mode 100644
index 51bee78..0000000
Binary files a/data/feature/__pycache__/feature_extractor.cpython-310.pyc and /dev/null differ
diff --git a/data/feature/__pycache__/state_manager.cpython-310.pyc b/data/feature/__pycache__/state_manager.cpython-310.pyc
deleted file mode 100644
index af5807a..0000000
Binary files a/data/feature/__pycache__/state_manager.cpython-310.pyc and /dev/null differ
diff --git a/data/provider/__pycache__/data_provider.cpython-310.pyc b/data/provider/__pycache__/data_provider.cpython-310.pyc
index 27b7b42..a1dc587 100644
Binary files a/data/provider/__pycache__/data_provider.cpython-310.pyc and b/data/provider/__pycache__/data_provider.cpython-310.pyc differ
diff --git a/data/provider/data_bento/__pycache__/databento_file_provider.cpython-310.pyc b/data/provider/data_bento/__pycache__/databento_file_provider.cpython-310.pyc
index eb7cb6b..932607b 100644
Binary files a/data/provider/data_bento/__pycache__/databento_file_provider.cpython-310.pyc and b/data/provider/data_bento/__pycache__/databento_file_provider.cpython-310.pyc differ
diff --git a/data/utils/__pycache__/indicators.cpython-310.pyc b/data/utils/__pycache__/indicators.cpython-310.pyc
deleted file mode 100644
index 28e4ca8..0000000
Binary files a/data/utils/__pycache__/indicators.cpython-310.pyc and /dev/null differ
diff --git a/envs/__pycache__/trading_env.cpython-310.pyc b/envs/__pycache__/trading_env.cpython-310.pyc
index ff5e2c4..fcdb4a3 100644
Binary files a/envs/__pycache__/trading_env.cpython-310.pyc and b/envs/__pycache__/trading_env.cpython-310.pyc differ
diff --git a/main.py b/main.py
index 9cbb8d7..0d8e2e4 100644
--- a/main.py
+++ b/main.py
@@ -1,4 +1,3 @@
-# main.py
 import sys
 import os
 import hydra
@@ -29,8 +28,6 @@ def run_training(cfg: DictConfig):
     Args:
         cfg: Hydra configuration object containing all parameters
     """
-    # Log the configuration
-    log.info(f"Configuration:\n{OmegaConf.to_yaml(cfg)}")
 
     # Get output directory
     output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir
@@ -39,7 +36,7 @@ def run_training(cfg: DictConfig):
 
     # 1. Initialize data provider and manager
     log.info("Initializing data provider")
-    provider = DabentoFileProvider(cfg.data.dir)
+    provider = DabentoFileProvider(cfg.data.data_dir)
     data_manager = DataManager(provider, logger=log)
 
     # 2. Set up simulator
@@ -77,45 +74,6 @@ def run_training(cfg: DictConfig):
     log.info("Creating multi-branch transformer model")
     model = MultiBranchTransformer(**cfg.model, device=device)
 
-
-
-
-
-    # In your training.py or main.py, after creating the model:
-    model_config_str = str(cfg.model)
-    model_str = str(model)
-    log.info(f"Model config: {model_config_str}")
-    log.info(f"Model structure: {model_str}")
-
-    # Test a forward pass with dummy input to catch dimension issues:
-    try:
-        # Create dummy input matching your expected dimensions
-        dummy_input = {
-            'hf_features': torch.zeros((1, model.hf_seq_len, model.hf_feat_dim)),
-            'mf_features': torch.zeros((1, model.mf_seq_len, model.mf_feat_dim)),
-            'lf_features': torch.zeros((1, model.lf_seq_len, model.lf_feat_dim)),
-            'static_features': torch.zeros((1, model.static_feat_dim))
-        }
-        dummy_input = {k: v.to(device) for k, v in dummy_input.items()}
-
-        # Test forward pass
-        with torch.no_grad():
-            output = model(dummy_input)
-        log.info(f"Model forward pass successful! Output shape: {[o.shape for o in output]}")
-    except Exception as e:
-        log.error(f"Error during model forward pass: {str(e)}")
-
-
-
-
-
-
-
-
-
-
-
-
     # 7. Set up training callbacks
     callbacks = [
         ModelCheckpointCallback(
@@ -190,4 +148,4 @@ if __name__ == "__main__":
     # For quick testing, add default arg
     if len(sys.argv) == 1 and "quick_test" not in sys.argv:
         sys.argv.extend(["quick_test=true"])
-    run_training()
\ No newline at end of file
+    run_training()
diff --git a/simulation/market_simulator.py b/simulation/market_simulator.py
index 199f860..444ab6d 100644
--- a/simulation/market_simulator.py
+++ b/simulation/market_simulator.py
@@ -83,7 +83,7 @@ class MarketSimulator:
                     break
 
         # If still not initialized, try bars
-        if not valid_price_found and not bars_df.empty:
+        if not valid_price_found and bars_df is not None and not bars_df.empty:
             for i, row in bars_df.iterrows():
                 if 'open' in row and pd.notna(row['open']) and row['open'] > 0:
                     self.current_price = row['open']
diff --git a/simulation/simulator.py b/simulation/simulator.py
index 5d76074..e34d028 100644
--- a/simulation/simulator.py
+++ b/simulation/simulator.py
@@ -179,23 +179,41 @@ class Simulator:
 
         # Print data stats
         for key, df in data_dict.items():
-            if not df.empty:
-                self._log(f"Loaded {len(df)} rows of {key} data")
+            if isinstance(df, pd.DataFrame):
+                if not df.empty:
+                    self._log(f"Loaded {len(df)} rows of {key} data")
+                else:
+                    self._log(f"No data loaded for {key}")
             else:
-                self._log(f"No data loaded for {key}")
+                self._log(f"Data for {key} is not a DataFrame type: {type(df)}")
 
         # Initialize components
         # First the market simulator
         quotes_df = data_dict.get('quotes', pd.DataFrame())
         trades_df = data_dict.get('trades', pd.DataFrame())
 
-        # Get the appropriate bar data
         bars_df = None
         for tf in ['bars_1m', 'bars_5m', 'bars_1d']:
-            if tf in data_dict and not data_dict[tf].empty:
+            if tf in data_dict and isinstance(data_dict[tf], pd.DataFrame) and not data_dict[tf].empty:
                 bars_df = data_dict[tf]
                 break
 
+        # Ensure we have valid DataFrames for all inputs
+        quotes_df = data_dict.get('quotes', pd.DataFrame())
+        if not isinstance(quotes_df, pd.DataFrame):
+            quotes_df = pd.DataFrame()
+
+        trades_df = data_dict.get('trades', pd.DataFrame())
+        if not isinstance(trades_df, pd.DataFrame):
+            trades_df = pd.DataFrame()
+
+        status_df = data_dict.get('status', pd.DataFrame())
+        if not isinstance(status_df, pd.DataFrame):
+            status_df = pd.DataFrame()
+
+        # Now initialize simulators with proper DataFrame objects
+        self.market_simulator.initialize_from_data(quotes_df, trades_df, bars_df, status_df)
+
         status_df = data_dict.get('status', pd.DataFrame())
 
         # Initialize simulators
diff --git a/utils/logger.py b/utils/logger.py
index d9df457..c1ed2aa 100644
--- a/utils/logger.py
+++ b/utils/logger.py
@@ -47,9 +47,14 @@ class EnhancedLogger:
 
         # Create formatter
         formatter = logging.Formatter(
-            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+            '%(asctime)s - %(levelname)s - %(message)s'
         )
 
+        # formatter = logging.Formatter(
+        #     '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+        # )
+        #
+
         # Create console handler
         console_handler = logging.StreamHandler(sys.stdout)
         console_handler.setLevel(console_level)
