{
  "termination_reason": "user_interrupt",
  "total_episodes": 34,
  "total_updates": 34,
  "total_steps": 8704,
  "training_hours": 0.2460451733333333,
  "final_performance": 0.0,
  "best_performance": 0.0,
  "continuous_training_session_duration": 1182.4295983314514,
  "continuous_training_best_reward": 0.0,
  "continuous_training_adaptations": 0,
  "continuous_training_evaluations": 7,
  "continuous_training_mode": "production",
  "adaptation_history": [],
  "evaluation_history": [
    {
      "mean_reward": -2.5599999999999894,
      "timestamp": "2025-06-06T23:26:37.152959",
      "evaluation_episodes": 0
    },
    {
      "mean_reward": -2.5599999999999894,
      "timestamp": "2025-06-06T23:28:35.778690",
      "evaluation_episodes": 0
    },
    {
      "mean_reward": -2.5599999999999894,
      "timestamp": "2025-06-06T23:30:21.849779",
      "evaluation_episodes": 0
    },
    {
      "mean_reward": -2.5599999999999894,
      "timestamp": "2025-06-06T23:32:17.127159",
      "evaluation_episodes": 0
    },
    {
      "mean_reward": -2.5599999999999894,
      "timestamp": "2025-06-06T23:34:16.620405",
      "evaluation_episodes": 0
    },
    {
      "mean_reward": -2.5599999999999894,
      "timestamp": "2025-06-06T23:36:03.771284",
      "evaluation_episodes": 0
    },
    {
      "mean_reward": -24.234448251905654,
      "timestamp": "2025-06-06T23:42:19.212504",
      "evaluation_episodes": 0
    }
  ],
  "final_quality_range": [
    0.7,
    1.0
  ],
  "timestamp": "2025-06-06T23:42:21.341491"
}