
# config/training/ppo.yaml
# PPO training configuration - synchronized with TrainingConfig

# Learning parameters
lr: 3e-4
gamma: 0.99
gae_lambda: 0.95
clip_eps: 0.2
critic_coef: 0.5
entropy_coef: 0.01
max_grad_norm: 0.5
best_model_path: "best_model"
best_model_metric: "best_model_metric.json"

# Training process
n_epochs: 10
batch_size: 64
buffer_size: 4096
n_episodes_per_update: 8
total_updates: 100

# Device and performance
device: "auto"  # "auto", "cuda", "cpu", or "mps"