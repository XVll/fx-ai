# Training parameters for PPO algorithm

# Learning parameters
lr: 3e-4                # Learning rate
gamma: 0.99             # Discount factor
gae_lambda: 0.95        # Lambda for Generalized Advantage Estimation
clip_eps: 0.2           # PPO clipping parameter
critic_coef: 0.5        # Value function coefficient
entropy_coef: 0.01      # Entropy coefficient
max_grad_norm: 0.5      # Maximum gradient norm

# Training process
n_epochs: 10            # Number of optimization epochs per update
batch_size: 64          # Minibatch size for optimization
buffer_size: 2048       # Size of replay buffer
n_episodes_per_update: 8  # Number of episodes to collect before updating
total_updates: 100      # Total number of updates

# Device and performance
device: "auto"          # "auto", "cuda", "cpu", or "mps"