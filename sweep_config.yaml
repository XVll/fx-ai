# sweep_config.yaml
program: main.py
method: bayes
metric:
  name: episode/mean_reward
  goal: maximize

parameters:
  training.lr:
    min: 0.00001
    max: 0.001
    distribution: log_uniform

  training.gamma:
    min: 0.9
    max: 0.999
    distribution: uniform

  training.gae_lambda:
    min: 0.9
    max: 0.99
    distribution: uniform

  training.clip_eps:
    min: 0.1
    max: 0.3
    distribution: uniform

  training.n_epochs:
    values: [5, 8, 10, 12, 15]

  training.entropy_coef:
    min: 0.0
    max: 0.05
    distribution: uniform

  model.d_model:
    values: [32, 64, 96, 128]

  model.d_fused:
    values: [128, 192, 256, 384]

  model.hf_layers:
    values: [1, 2, 3]

  model.mf_layers:
    values: [1, 2, 3]

  env.reward_scaling:
    min: 0.1
    max: 10.0
    distribution: log_uniform

  env.trade_penalty:
    min: 0.0
    max: 0.2
    distribution: uniform